{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kM8x0N86SQW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers,models\n",
        "from tensorflow.keras.datasets import fashion_mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zc3g_OPF62v6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef1cc4c1-b1cc-448c-f455-2cadd6753007"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "#loading the mnist dataset for usage\n",
        "(train_images,train_labels),(test_images,test_labels)=fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ua5EqByr7Wy2"
      },
      "outputs": [],
      "source": [
        "#why need to do :Neural networks often perform better when the input data has a consistent and relatively small scale.\n",
        "train_images=train_images/255.0\n",
        "test_images=test_images/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1b1FPv5Z8WWk"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Input(shape=(28, 28)),  # Correct input shape\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mDVX1rV-UJK"
      },
      "outputs": [],
      "source": [
        "# The model is compiled using the Adam optimizer with a custom learning rate\n",
        "#Trains the model for 5 epochs with a batch size of 128. It uses 20% of the training data as the validation set\n",
        "#The function captures the validation accuracy\n",
        "def train_model(learning_rate):\n",
        "    model = create_model()\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(train_images, train_labels, epochs=5, batch_size=128,\n",
        "                        validation_split=0.2, verbose=0)\n",
        "\n",
        "    # Debugging statement to ensure the accuracy is being captured\n",
        "    #print(f\"Training complete for learning rate {learning_rate}. Validation accuracy: {history.history['val_accuracy'][-1]}\")\n",
        "\n",
        "    val_accuracy = history.history['val_accuracy'][-1]\n",
        "    return val_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eihp6ckTAd3a"
      },
      "outputs": [],
      "source": [
        "#the binary_search_learning_rate function attempts to find the optimal learning model using binary search(the learning rate is a hyperparameter)\n",
        "#this hyperparameter is responsibele for how much the change the model in response to the estimal error during training  phase\n",
        "#the goal of the funtion is to find the learning rate that maximize the model validation accuracy\n",
        "def binary_search_learning_rate(low, high, threshold=0.0001):\n",
        "    best_learning_rate = 0\n",
        "    best_accuracy = 0\n",
        "\n",
        "    # Train once with low and high learning rates to avoid repeated computation\n",
        "    accuracy_low = train_model(low)\n",
        "    accuracy_high = train_model(high)\n",
        "\n",
        "    while (high - low) > threshold:\n",
        "        mid = (low + high) / 2\n",
        "\n",
        "        # Train model with mid learning rate\n",
        "        accuracy_mid = train_model(mid)\n",
        "        #print(f\"Learning rate: {mid:.5f}, Validation accuracy: {accuracy_mid:.4f}\")\n",
        "\n",
        "        # Update the best learning rate if mid performs better\n",
        "        if accuracy_mid > best_accuracy:\n",
        "            best_accuracy = accuracy_mid\n",
        "            best_learning_rate = mid\n",
        "\n",
        "        # Adjust bounds based on performance of mid\n",
        "        if accuracy_mid > accuracy_low:\n",
        "            # Move lower bound up, no need to retrain at new low\n",
        "            low = mid\n",
        "            accuracy_low = accuracy_mid  # Update low accuracy to mid accuracy\n",
        "        else:\n",
        "            # Move upper bound down, no need to retrain at new high\n",
        "            high = mid\n",
        "            accuracy_high = accuracy_mid  # Update high accuracy to mid accuracy\n",
        "\n",
        "    return best_learning_rate, best_accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQ1gBXlPwTFf",
        "outputId": "394cb3c0-8f2e-41a5-ce4b-ef46e6624265"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning rate: 0.50005, Validation accuracy: 0.1028\n",
            "Learning rate: 0.25007, Validation accuracy: 0.1045\n",
            "Learning rate: 0.12509, Validation accuracy: 0.5602\n",
            "Learning rate: 0.06259, Validation accuracy: 0.7776\n",
            "Learning rate: 0.03135, Validation accuracy: 0.8494\n",
            "Learning rate: 0.04697, Validation accuracy: 0.8403\n",
            "Learning rate: 0.03916, Validation accuracy: 0.7859\n",
            "Learning rate: 0.03525, Validation accuracy: 0.8464\n",
            "Learning rate: 0.03330, Validation accuracy: 0.8393\n",
            "Learning rate: 0.03232, Validation accuracy: 0.8410\n",
            "Learning rate: 0.03184, Validation accuracy: 0.8399\n",
            "Learning rate: 0.03159, Validation accuracy: 0.8476\n",
            "Learning rate: 0.03147, Validation accuracy: 0.8314\n",
            "Learning rate: 0.03141, Validation accuracy: 0.8192\n",
            "Optimal Learning Rate: 0.031346874999999996, Validation Accuracy: 0.8494166731834412\n"
          ]
        }
      ],
      "source": [
        "optimal_lr, optimal_acc = binary_search_learning_rate(0.0001, 1.0)\n",
        "\n",
        "print(f\"Optimal Learning Rate: {optimal_lr}, Validation Accuracy: {optimal_acc}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}